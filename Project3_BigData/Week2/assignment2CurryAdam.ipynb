{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "committed-mexican",
   "metadata": {},
   "source": [
    "## Assignment 2.1\n",
    "\n",
    " For this assignment, we will be working with the CSV data found in the `data/external/tidynomicon` folder.  Specifically, we will be using with the `measurements.csv`, `person.csv`, `site.csv`, and `visited.csv` files. \n",
    "\n",
    " If you are running on JupyterHub hosted on the BU Data Science Cluster, you can load data from the cluster's Amazon S3-compatible data storage.  The following code demonstrates how to load the `site.csv` data into a Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driving-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "\n",
    "\n",
    "def read_cluster_csv(file_path, endpoint_url='https://storage.budsc.midwest-datascience.com'):\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    return pd.read_csv(s3.open(file_path, mode='rb'))\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "results_dir = current_dir.joinpath('results')\n",
    "kv_data_dir = results_dir.joinpath('kvdb')\n",
    "kv_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "people_json = kv_data_dir.joinpath('people.json')\n",
    "visited_json = kv_data_dir.joinpath('visited.json')\n",
    "sites_json = kv_data_dir.joinpath('sites.json')\n",
    "measurements_json = kv_data_dir.joinpath('measurements.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "finnish-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KVDB(object):\n",
    "    def __init__(self, db_path):\n",
    "        self._db_path = Path(db_path)\n",
    "        self._db = {}\n",
    "        self._load_db()\n",
    "\n",
    "    def _load_db(self):\n",
    "        if self._db_path.exists():\n",
    "            with open(self._db_path) as f:\n",
    "                self._db = json.load(f)\n",
    "\n",
    "    def get_value(self, key):\n",
    "        return self._db.get(key)\n",
    "\n",
    "    def set_value(self, key, value):\n",
    "        self._db[key] = value\n",
    "\n",
    "    def save(self):\n",
    "        with open(self._db_path, 'w') as f:\n",
    "            json.dump(self._db, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sticky-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sites_kvdb():\n",
    "    db = KVDB(sites_json)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/site.csv')\n",
    "    for site_id, group_df in df.groupby('site_id'):\n",
    "        db.set_value(site_id, group_df.to_dict(orient='records')[0])\n",
    "    db.save()\n",
    "\n",
    "def create_people_kvdb():\n",
    "    db = KVDB(people_json)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/person.csv')\n",
    "    for person_id, group_df in df.groupby('person_id'):\n",
    "        db.set_value(person_id, group_df.to_dict(orient='records')[0])\n",
    "    db.save()\n",
    "\n",
    "def create_visits_kvdb():\n",
    "    db = KVDB(visited_json)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/visited.csv')\n",
    "    for key, group_df in df.groupby(['visit_id', 'site_id']):\n",
    "        db.set_value(str(key), group_df.to_dict(orient='records')[0])\n",
    "    db.save()\n",
    "\n",
    "def create_measurements_kvdb():\n",
    "    db = KVDB(measurements_json)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/measurements.csv')\n",
    "    for key, group_df in df.groupby(['person_id','visit_id','quantity']):\n",
    "        db.set_value(str(key), group_df.to_dict(orient='records')[0])\n",
    "    db.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "major-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sites_kvdb()\n",
    "create_people_kvdb()\n",
    "create_visits_kvdb()\n",
    "create_measurements_kvdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-collins",
   "metadata": {},
   "source": [
    "### Assignment 2.2\n",
    "\n",
    " Now we will create a simple document database using the `tinydb` library. TinyDB stores its data as a JSON file. For this assignment, you will store the TinyDB database in `dsc650/assignments/assignment02/results/patient-info.json`.  You will store a document for each person in the database which should look like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "negative-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from tinydb import TinyDB\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "results_dir = current_dir.joinpath('results')\n",
    "kv_data_dir = results_dir.joinpath('kvdb')\n",
    "kv_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _load_json(json_path):\n",
    "    with open(json_path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "class DocumentDB(object):\n",
    "    def __init__(self, db_path):\n",
    "        ## You can use the code from the previous exmaple if you would like\n",
    "        people_json = kv_data_dir.joinpath('people.json')\n",
    "        visited_json = kv_data_dir.joinpath('visited.json')\n",
    "        sites_json = kv_data_dir.joinpath('sites.json')\n",
    "        measurements_json = kv_data_dir.joinpath('measurements.json')\n",
    "        self._db_path = Path(db_path)\n",
    "        self._db = None\n",
    "        ## TODO\n",
    "        self._person_lookup = _load_json(people_json)\n",
    "        self._visited_lookup = _load_json(visited_json)\n",
    "        self._sites_lookup = _load_json(sites_json)\n",
    "        self._measurements_lookup = _load_json(measurements_json)\n",
    "        self._load_db()\n",
    "        \n",
    "    def _get_site(self, site_id):\n",
    "        return self._site_lookup[str(site_id)]\n",
    "    \n",
    "    def _get_measurements(self, person_id):\n",
    "        measurements = []\n",
    "        for values in self._measurements_lookup.values():\n",
    "            measurements.extend([value for value in values if str(['person_id']) == str(person_id)])\n",
    "            return measurements\n",
    "    \n",
    "    def _get_visit(self, visit_id):\n",
    "        visits = self._visited_lookup.get(str(visit_id))\n",
    "        ## TODO: site_id = ...\n",
    "        site_id = set([visits['site_id'] for visits in visits])\n",
    "        ## TODO: site = ...\n",
    "        site = self._get_site(site_id)\n",
    "        visit['site'] = site\n",
    "        return visit\n",
    "    \n",
    "    def _load_db(self):\n",
    "        self._db = TinyDB(self._db_path)\n",
    "        persons = self._person_lookup.items()\n",
    "        for person_id, record in persons:\n",
    "            measurements = self._get_measurements(person_id)\n",
    "            visit_ids = set([measurement['visit_id'] for measurement in measurements])\n",
    "            visits = []\n",
    "            for visit_id in visit_ids:\n",
    "                visit = self._get_visit(visit_id)\n",
    "                visit['measurements'] = [\n",
    "                    measurement for measurement in measurements\n",
    "                    if visit_id == measurement['visit_id']\n",
    "                ]\n",
    "                visits.append(visit)\n",
    "                record['visits'] = visits\n",
    "            self._db.insert(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stone-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = results_dir.joinpath('patient-info.json')\n",
    "if db_path.exists():\n",
    "    os.remove(db_path)\n",
    "\n",
    "db = DocumentDB(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-joining",
   "metadata": {},
   "source": [
    "### Assignment 2.3\n",
    "\n",
    " In this part, you will create a SQLite database that you will store in `dsc650/assignments/assignment02/results/patient-info.db`.  The `dsc650/assignments/assignment02/rdbms.ipynb` file should contain code to assist you in the creation of this database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "interior-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "results_dir = current_dir.joinpath('results')\n",
    "kv_data_dir = results_dir.joinpath('kvdb')\n",
    "kv_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_cluster_csv(file_path, endpoint_url='https://storage.budsc.midwest-datascience.com'):\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    return pd.read_csv(s3.open(file_path, mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-psychology",
   "metadata": {},
   "source": [
    "## Create and Load Measurements Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "polar-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_measurements_table(conn):\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS measurements (\n",
    "        visit_id integer NOT NULL,\n",
    "        person_id text NOT NULL,\n",
    "        quantity text,\n",
    "        reading real,\n",
    "        FOREIGN KEY (visit_id) REFERENCES visits (visit_id),\n",
    "        FOREIGN KEY (person_id) REFERENCES people (people_id)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql)\n",
    "    \n",
    "def load_measurements_table(conn):\n",
    "    create_measurements_table(conn)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/measurements.csv')\n",
    "    measurements = df.values\n",
    "    c = conn.cursor()\n",
    "    c.execute('DELETE FROM measurements;') # Delete data if exists\n",
    "    c.executemany('INSERT INTO measurements VALUES (?,?,?,?)', measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-stuff",
   "metadata": {},
   "source": [
    "## Create and Load People Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "banner-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_people_table(conn):\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS people (\n",
    "        person_id text PRIMARY KEY,\n",
    "        personal_name text,\n",
    "        family_name text\n",
    "        );\n",
    "    \"\"\"\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql)\n",
    "    \n",
    "def load_people_table(conn):\n",
    "    create_people_table(conn)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/person.csv')\n",
    "    people = df.values\n",
    "    c = conn.cursor()\n",
    "    c.execute('DELETE FROM people;') # Delete data if exists\n",
    "    c.executemany('INSERT INTO people VALUES (?,?,?)', people)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-andorra",
   "metadata": {},
   "source": [
    "## Create and Load Sites Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "different-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sites_table(conn):\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS sites (\n",
    "        site_id text PRIMARY KEY,\n",
    "        latitude double NOT NULL,\n",
    "        longitude double NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql)\n",
    "\n",
    "def load_sites_table(conn):\n",
    "    create_sites_table(conn)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/site.csv')\n",
    "    sites = df.values\n",
    "    c = conn.cursor()\n",
    "    c.execute('DELETE FROM sites;') # Delete data if exists\n",
    "    c.executemany('INSERT INTO sites VALUES (?,?,?)', sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-prince",
   "metadata": {},
   "source": [
    "## Create and Load Visits Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "naughty-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visits_table(conn):\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS visits (\n",
    "        visit_id integer PRIMARY KEY,\n",
    "        site_id text NOT NULL,\n",
    "        visit_date text,\n",
    "        FOREIGN KEY (site_id) REFERENCES sites (site_id)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql)\n",
    "\n",
    "def load_visits_table(conn):\n",
    "    create_visits_table(conn)\n",
    "    df = read_cluster_csv('data/external/tidynomicon/visited.csv')\n",
    "    visits = df.values\n",
    "    c = conn.cursor()\n",
    "    c.execute('DELETE FROM visits;') # Delete data if exists\n",
    "    c.executemany('INSERT INTO visits VALUES (?,?,?)', visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-victory",
   "metadata": {},
   "source": [
    "## Create DB and Load Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "sitting-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = results_dir.joinpath('patient-info.db')\n",
    "conn = sqlite3.connect(str(db_path))\n",
    "#TODO: Uncomment once functions completed\n",
    "load_people_table(conn) \n",
    "load_sites_table(conn)\n",
    "load_visits_table(conn)\n",
    "load_measurements_table(conn)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-young",
   "metadata": {},
   "source": [
    "### Assignment 2.4\n",
    "\n",
    " Go to the [Wikidata Query Service][wikidata-query] website and perform the following SPARQL query. \n",
    "\n",
    "```sparql\n",
    "#Recent Events\n",
    " SELECT ?event ?eventLabel ?date\n",
    " WHERE\n",
    " {\n",
    "    # find events\n",
    "    ?event wdt:P31/wdt:P279* wd:Q1190554.\n",
    "    # with a point in time or start date\n",
    "    OPTIONAL { ?event wdt:P585 ?date. }\n",
    "    OPTIONAL { ?event wdt:P580 ?date. }\n",
    "    # but at least one of those\n",
    "    FILTER(BOUND(?date) && DATATYPE(?date) = xsd:dateTime).\n",
    "    # not in the future, and not more than 31 days ago\n",
    "    BIND(NOW() - ?date AS ?distance).\n",
    "    FILTER(0 <= ?distance && ?distance < 31).\n",
    "    # and get a label as well\n",
    "    OPTIONAL {\n",
    "        ?event rdfs:label ?eventLabel.\n",
    "        FILTER(LANG(?eventLabel) = \"en\").\n",
    "    }\n",
    " }\n",
    "# limit to 10 results so we don't timeout\n",
    " LIMIT 10\n",
    "```\n",
    "\n",
    " Modify the query so that the column order is `date`, `event`, and `eventLabel` instead of `event`, `eventLabel`, and `date`. Download the results as a JSON file and copy the results to `dsc650/assignments/assignment02/results/wikidata-query.json`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
