{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "import threading\n",
    "import datetime  as dt\n",
    "import json\n",
    "\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin.new_topic import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters \n",
    "\n",
    "> **TODO:** Change the configuration prameters to the appropriate values for your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': ['kafka.kafka.svc.cluster.local:9092'],\n",
       " 'first_name': 'Adam',\n",
       " 'last_name': 'Curry',\n",
       " 'client_id': 'CurryAdam',\n",
       " 'topic_prefix': 'CurryAdam'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    bootstrap_servers=['kafka.kafka.svc.cluster.local:9092'],\n",
    "    first_name='Adam',\n",
    "    last_name='Curry'\n",
    ")\n",
    "\n",
    "config['client_id'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "config['topic_prefix'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    anon=True,\n",
    "    client_kwargs={\n",
    "        'endpoint_url': endpoint_url\n",
    "    }\n",
    ")\n",
    "\n",
    "acceleration_columns = [\n",
    "    'offset',\n",
    "    'id',\n",
    "    'ride_id',\n",
    "    'uuid',\n",
    "    'x',\n",
    "    'y',\n",
    "    'z',\n",
    "#     't'\n",
    "]\n",
    "Acceleration = namedtuple('Acceleration', acceleration_columns)\n",
    "def read_accelerations():\n",
    "    df = pq.ParquetDataset(\n",
    "        's3://data/processed/bdd/accelerations',\n",
    "        filesystem=s3\n",
    "    ).read_pandas().to_pandas()\n",
    "    \n",
    "    df = df[acceleration_columns].sort_values(by=['offset'])\n",
    "    \n",
    "    records = [Acceleration(*record) for record in df.to_records(index=False)]\n",
    "    \n",
    "    return records\n",
    "accelerations = read_accelerations()\n",
    "\n",
    "location_columns = [\n",
    "    'offset',\n",
    "    'id',\n",
    "    'ride_id',\n",
    "    'uuid',\n",
    "    'course',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'geohash',\n",
    "    'speed',\n",
    "    'accuracy',\n",
    "#     't'\n",
    "]\n",
    "Location = namedtuple('Location', location_columns)\n",
    "def read_locations():\n",
    "    df = pq.ParquetDataset(\n",
    "        's3://data/processed/bdd/locations',\n",
    "        filesystem=s3\n",
    "    ).read_pandas().to_pandas()\n",
    "    \n",
    "    df = df[location_columns].sort_values(by=['offset'])\n",
    "    \n",
    "    records = [Location(*record) for record in df.to_records(index=False)]\n",
    "    \n",
    "    return records\n",
    "    \n",
    "locations = read_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Utility Function\n",
    "\n",
    "The `create_kafka_topic` helps create a Kafka topic based on your configuration settings.  For instance, if your first name is *John* and your last name is *Doe*, `create_kafka_topic('locations')` will create a topic with the name `DoeJohn-locations`.  The function will not create the topic if it already exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"CurryAdam-locations\" already exists\n",
      "Topic \"CurryAdam-accelerations\" already exists\n"
     ]
    }
   ],
   "source": [
    "def create_kafka_topic(topic_name, config=config, num_partitions=1, replication_factor=1):\n",
    "    bootstrap_servers = config['bootstrap_servers']\n",
    "    client_id = config['client_id']\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    name = '{}-{}'.format(topic_prefix, topic_name)\n",
    "    \n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=bootstrap_servers, \n",
    "        client_id=client_id\n",
    "    )\n",
    "    \n",
    "    topic = NewTopic(\n",
    "        name=name,\n",
    "        num_partitions=num_partitions,\n",
    "        replication_factor=replication_factor\n",
    "    )\n",
    "\n",
    "    topic_list = [topic]\n",
    "    try:\n",
    "        admin_client.create_topics(new_topics=topic_list)\n",
    "        print('Created topic \"{}\"'.format(name))\n",
    "    except TopicAlreadyExistsError as e:\n",
    "        print('Topic \"{}\" already exists'.format(name))\n",
    "    \n",
    "create_kafka_topic('locations')\n",
    "create_kafka_topic('accelerations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka Producer\n",
    "\n",
    "The following code creates a `KafkaProducer` object which you can use to send Python objects that are serialized as JSON.\n",
    "\n",
    "**Note:** This producer serializes Python objects as JSON. This means that object must be JSON serializable.  As an example, Python `DateTime` values are not JSON serializable and must be converted to a string (e.g. ISO 8601) or a numeric value (e.g. a Unix timestamp) before being sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "  bootstrap_servers=config['bootstrap_servers'],\n",
    "  value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Data Function\n",
    "\n",
    "The `send_data` function sends a Python object to a Kafka topic. This function adds the `topic_prefix` to the topic so `send_data('locations', data)` sends a JSON serialized message to `DoeJohn-locations`. The function also registers callbacks to let you know if the message has been sent or if an error has occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_send_success(record_metadata):\n",
    "    print('Message sent:\\n    Topic: \"{}\"\\n    Partition: {}\\n    Offset: {}'.format(\n",
    "        record_metadata.topic,\n",
    "        record_metadata.partition,\n",
    "        record_metadata.offset\n",
    "    ))\n",
    "    \n",
    "def on_send_error(excp):\n",
    "    print('I am an errback', exc_info=excp)\n",
    "    # handle exception\n",
    "\n",
    "def send_data(topic, data, config=config, producer=producer, msg_key=None):\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    topic_name = '{}-{}'.format(topic_prefix, topic)\n",
    "    \n",
    "    if msg_key is not None:\n",
    "        key = msg_key\n",
    "    else:\n",
    "        key = uuid.uuid4().hex\n",
    "    \n",
    "    producer.send(\n",
    "        topic_name, \n",
    "        value=data,\n",
    "        key=key.encode('utf-8')\n",
    "    ).add_callback(on_send_success).add_errback(on_send_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent:\n",
      "    Topic: \"CurryAdam-locations\"\n",
      "    Partition: 0\n",
      "    Offset: 38\n"
     ]
    }
   ],
   "source": [
    "example_data = dict(\n",
    "    key1='value1',\n",
    "    key2='value2'\n",
    ")\n",
    "\n",
    "send_data('locations', example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "#https://www.youtube.com/watch?v=HIz0pUXhM3U\n",
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "base_dir = '/home/jovyan/dsc650/data/processed/bdd/'\n",
    "accelerations=base_dir+'accelerations/'\n",
    "locations=base_dir+'locations/'\n",
    "time_dir=os.listdir(locations)\n",
    "\n",
    "test_dir = '/home/jovyan/dsc650/data/processed/bdd/locations//t=007.8/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out the names from each folder to iterate through each message\n",
    "def time_path(folder_path):\n",
    "    folder_dir = folder_path\n",
    "    time_dir = os.listdir(folder_dir)\n",
    "    time_l = list(set([float(x.split('=')[1]) for x in time]))\n",
    "    time_dict = {}\n",
    "    for t in time:\n",
    "        time_dict[float(t.split('=')[1])]=t\n",
    "    return time_l, time_dict, folder_dir\n",
    "\n",
    "#time_path(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send(f):\n",
    "    i = 0.0\n",
    "    time_l, time_dict, folder_dir = time_path(f)\n",
    "    event = threading.Event()\n",
    "    for t in time_l:\n",
    "        final_dir = folder_dir+'/'+time_dict[t]+'/'\n",
    "        pq = read_parq(final_dir)\n",
    "        event.wait(t-i)\n",
    "        curr_time = dt.datetime.now()\n",
    "        i=t\n",
    "        send_data('locations',pq)\n",
    "send(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
